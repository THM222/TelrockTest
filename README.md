# TelrockTest

It's a dog-eat-dog world, and today it's an AI-Robot-Dog that gives the competitive edge to a company in any given sector.

Technology appears to be growing exponentially, so it is essential that companies adapt quickly, or risk going out of business. Companies also need to continuously provide their customers with something new or different, to keep them ahead of the competition. Agility and innovation are key. 

Companies are becoming more reliant on software; whether it is automating tasks to reduce errors, developing websites and mobile apps to market their products, or analysing big data to make the right decisions for the company to grow. Analysing data to decide how to improve your service could increase your yearly turnover by a million pounds. Meanwhile, one bug in your mobile app could mean losing hundreds of thousands of customers to your competitor overnight! In my opinion, this is part of what makes the role of a DevOps engineer crucial.

With cloud computing, companies are now able to provide Software as a Service (SaaS) through a third-party host. It allows companies to focus on their business, without worrying about the hardware. It opens up resources that can be used to improve existing services, or develop new services, to satisfy never-ending consumer demand. 

Innovation alone is not enough, though. There is an urgency to bring the idea to market as soon as possible. Thus, many current DevOps trends centre around automating the development process, to deliver a new feature or service more quickly and more efficiently. Some of these are discussed below.

I believe that one of the most important additions to the software development lifecycle is Continuous Integration and Continuous Delivery (CI/CD). The CI/CD pipeline enables you to automate the software delivery process, thus speeding up the release of new software. 

Following CI/CD best practices, developers test changes or new features on a configured testing machine, which is described in source files that allow you to recreate the machine at any time. Automated tests are then run on a machine that emulates a production environment, using tools such as Ansible, to determine whether the changes should be deployed or need to be developed further.

The CI/CD pipeline eliminates bugs caused by dependencies that exist on different developers’ machines, and automates the build and testing process. The CI/CD environment reduces the bottleneck caused by manual testing, allows bug-fixing to be completed sooner, and results in faster commits. Ultimately, it speeds up the release of a new feature or product to market.

Another popular trend in DevOps is virtualisation, and this ties in nicely with the CI/CD pipeline. The testing machines used to emulate production environments are often virtual machines (VMs), using software such as VirtualBox or VMWare Workstation to set up VMs. 

Hypervisors allow a company to invest in a single server that hosts multiple virtual servers, each performing a specific function or providing a particular service. Virtualisation means fewer hardware to manage and maintain, and provides a centralised location for management of all hardware and VMs. It reduces costs for hardware, hardware maintenance and electricity, as well as increases the efficiency of server management.

Another aspect of speeding up change and adaptation in IT, is infrastructure automation, which can basically be described as scripting environments. These could include installing an operating system, applying updates, configuring multiple machines at a time, configuring networks and much more.

Scripting is a powerful tool for management and maintenance of the entire IT infrastructure. The system administrator no longer fiddles with settings that are difficult to recreate on another machine. They simply write a script, tweak as necessary, and run on the target machine(s) with a single click or command. A number of open source tools exist for scripting, such as Chef and Puppet, and what makes many of these tools even more powerful is that they work cross-platform. This means you can apply changes to Windows, Mac and \*nix environments with the same script, which saves time – time that can be used to complete another important task.

With great power, comes great responsibility: Multi-billion-dollar software needs to be reliable, with as little downtime as possible, while continuously introducing new, innovative features to keep up with developments in the market. It is the role of the site reliability engineer to ensure all the boxes are ticked before a new release. 

Site Reliability Engineering (SRE) can be described as a discipline that manages continuous product enhancement, while maintaining a high-quality experience for the user. SRE combines development and operations (as do all DevOps roles, to be fair). It involves analysing problems in a system or an operational task, and finding a creative solution to automate the system or task. It could also involve making business decisions about the future of a product, and in which direction it should be developed. By analysing data and making decisions to improve existing systems and operations, SRE enhances the reliability of future systems. 

The complexity involved in automating manual operations or systems is an enticing prospect for me. It is important to have a wholesome understanding of the process, before being able to design the optimum solution. This is something I could do within infrastructure automation or SRE, and I would relish the opportunity to be involved in either of these.  

I am particularly interested in the additional challenge posed by SRE; “discovering” problems, designing efficient solutions, and developing these solutions with colleagues. I enjoy analysing systems, finding existing and potential problems, and it is something I believe I have the potential to excel in. I would love to be part of a team that is actively involved in finding solutions to these problems, and bringing these solutions into existence. I also believe I have the communication skills to outline such problems and explain the solutions to different audiences, including management and developers.

Finally, I would like to mention the importance of security in DevOps. The developers are under pressure to deliver new features and services as quickly as possible, which means cutting corners in the security of the code. This is a big risk in DevOps today, and some critics suggest DevOps will self-implode if it does not begin to address this issue. DevOps must evolve, and DevSecOps is a movement that aims to address this. Therefore, I expect there will be more tools to automate security in the near future, to assist developers in maintaining security standards as they code.

I hope to be given the opportunity to pursue a career in DevOps with Telrock.
